{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorboard \n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_list = [\"../../images/kitten.jpg\",\n",
    "                       \"../../images/dog.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nisha\\AppData\\Local\\Temp\\ipykernel_7300\\128243319.py:2: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From c:\\Users\\nisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\input.py:272: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From c:\\Users\\nisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\input.py:184: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From c:\\Users\\nisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\input.py:193: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From c:\\Users\\nisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\input.py:193: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\nisha\\AppData\\Local\\Temp\\ipykernel_7300\\128243319.py:5: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n"
     ]
    }
   ],
   "source": [
    "# Make a queue of filenames including all the images specified\n",
    "filename_queue = tf.compat.v1.train.string_input_producer(original_image_list)\n",
    "\n",
    "# Read an entire image file\n",
    "image_reader = tf.compat.v1.WholeFileReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 112, 3)\n",
      "Tensor(\"stack_3:0\", shape=(112, 112, 3), dtype=float32)\n",
      "(112, 112, 3)\n",
      "Tensor(\"stack_4:0\", shape=(112, 112, 3), dtype=float32)\n",
      "Tensor(\"stack_5:0\", shape=(2, 112, 112, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    # Coordinate the loading of image files\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.compat.v1.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    image_list = []\n",
    "    for i in range(len(original_image_list)):\n",
    "        # Read a whole file from the queue, the first returned value in the tuple is the\n",
    "        # filename which we are ignoring\n",
    "        _, image_file = image_reader.read(filename_queue)\n",
    "\n",
    "        # Decode the image as a JPEG file, this will return it into a Tensor which we can\n",
    "        # then use in training\n",
    "        image = tf.image.decode_jpeg(image_file)\n",
    "\n",
    "        # Get a tensor of resized images\n",
    "        image = tf.compat.v1.image.resize_images(image, [224, 224])\n",
    "        image.set_shape((224, 224, 3))\n",
    "\n",
    "        # Perform some image transformations \n",
    "        image = tf.image.flip_up_down(image)\n",
    "        image = tf.image.central_crop(image, central_fraction=0.5)\n",
    "\n",
    "        # Get an image tensor and print its value\n",
    "        image_array = sess.run(image)\n",
    "        print(image_array.shape)\n",
    "\n",
    "        # Converts a numpy array of the kind (224,224,3) to a tensor of shape (224,224,3)\n",
    "        image_tensor = tf.stack(image_array)\n",
    "\n",
    "        print(image_tensor)\n",
    "        image_list.append(image_tensor)\n",
    "    \n",
    "    # Finish off the filename queue coordinator\n",
    "    coord.request_stop()\n",
    "    coord.join(threads=threads)\n",
    "\n",
    "    # Converts all tensors to a single tensor with a 4th dimension\n",
    "    # 4 images of (224, 224, 3) can be accessed as (0, 224, 224, 3), (1,224,224, 3)...(3, 224,224, 3)\n",
    "    images_tensor = tf.stack(image_list)\n",
    "    print(images_tensor)\n",
    "\n",
    "    index = 0\n",
    "    # Write image summary\n",
    "    summary_writer = tf.compat.v1.summary.FileWriter(\"ImageTransformationsWithCoordinator\", graph=sess.graph)\n",
    "\n",
    "    # Write out all the images in one go\n",
    "    summary_str = sess.run(tf.compat.v1.summary.image(\"images\", images_tensor))\n",
    "    summary_writer.add_summary(summary_str)\n",
    "\n",
    "    summary_writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
