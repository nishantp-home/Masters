{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_goog_sp500_dataframe():\n",
    "    \"\"\"Returns a dataframe with the results (percentage change of adjusted prices with months) \n",
    "    for Google and S&P 500.\"\"\"\n",
    "    \n",
    "    filePath = \"E:\\\\Eskills-Academy-projects\\\\LearningTensorFlow\\\\data\\\\\"\n",
    "    googFile = filePath + \"GOOG.csv\"\n",
    "    spFILE = filePath + \"SP_500.csv\"\n",
    "\n",
    "    goog = pd.read_csv(googFile, sep=\",\", usecols=[0, 5], names=['Date', 'Goog'], header=0)\n",
    "    sp = pd.read_csv(spFILE, sep=\",\", usecols=[0, 5], names=['Date', 'SP500'], header=0)\n",
    "\n",
    "    goog['SP500'] = sp['SP500']\n",
    "\n",
    "    # Convert string format to date \n",
    "    goog['Date'] = pd.to_datetime(goog['Date'], format='%Y-%m-%d')\n",
    "\n",
    "    goog = goog.sort_values(['Date'], ascending=[True])\n",
    "    returns = goog[[key for key in dict(goog.dtypes) if dict(goog.dtypes)[key] in ['float64', 'int64']]].pct_change()\n",
    "\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_goog_sp500_logistic_data():\n",
    "    \"\"\"Returns a data frame with the results for google \n",
    "    and S&P 500 set up for logistic regression\"\"\"\n",
    "    returns = read_goog_sp500_dataframe()\n",
    "\n",
    "    # Add 'Intercept' column with 1 values\n",
    "    returns['Intercept'] = 1\n",
    "\n",
    "    # Leave out the first row \n",
    "    # Leave out the last row as it will not have a value for returns\n",
    "    # Resultant dataframe with the S&P 500 and intercept values of all \n",
    "\n",
    "    xData = np.array(returns[[\"SP500\", \"Intercept\"]][1:-1])\n",
    "    yData = (returns[\"Goog\"] > 0)[1:-1]\n",
    "\n",
    "    return (xData, yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xData, yData = read_goog_sp500_logistic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(yData, xData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the Logistic model\n",
    "result = logit.fit()\n",
    "\n",
    "# All values > 0.5 predict an up-day for Google\n",
    "predictions = (result.predict(xData) > 0.5)\n",
    "\n",
    "# Count the number of times the actual updays match the predicted updays\n",
    "accuratePredictionCount = (list(yData == predictions)).count(True)\n",
    "\n",
    "pctAccuracy = float(accuratePredictionCount) / float(len(predictions))\n",
    "print(\"Accuracy:\", pctAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.ones([1, 2]), name='W')\n",
    "b = tf.Variable(tf.zeros([2]), name='b')\n",
    "\n",
    "x = tf.compat.v1.placeholder(tf.float32, [None, 1], name='x')\n",
    "y_ = tf.compat.v1.placeholder(tf.float32, [None, 2], name='y_')\n",
    "\n",
    "y = tf.matmul(x, W) + b\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_xs = np.expand_dims(xData[:,0], axis=1)  # Convert to 2D array\n",
    "all_ys = np.array([([1, 0] if y_el == True else [0,1]) for y_el in yData])  # Convert to One-hot encoding  \n",
    "dataset_size = len(all_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainWithMultiplePointsPerEpoch(steps, train_step, batch_size):\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(steps):\n",
    "\n",
    "            if dataset_size == batch_size:\n",
    "                batch_start_idx = 0\n",
    "            elif dataset_size < batch_size:\n",
    "                raise ValueError(\"data set size: %d, must be greater than the batch_size: %d\"%(dataset_size, batch_size))\n",
    "            else:\n",
    "                batch_start_idx =(step*batch_size) % dataset_size\n",
    "\n",
    "            batch_end_idx = batch_start_idx + batch_size\n",
    "\n",
    "            # Access the x and y values in batches\n",
    "            batch_xs = all_xs[batch_start_idx : batch_end_idx]\n",
    "            batch_ys = all_ys[batch_start_idx : batch_end_idx]\n",
    "\n",
    "            # Reshape the 1-D arrays as 2D feature vectors with many rows and 1-column\n",
    "            feed = {x: batch_xs, y_:batch_ys}\n",
    "            sess.run(train_step, feed_dict=feed)\n",
    "\n",
    "            # Print result to scren for every 500 iterations\n",
    "            if (step + 1) % 500 == 0:\n",
    "                print(\"After %d iterations\"%step)\n",
    "                print(\"W:\", sess.run(W))\n",
    "                print(\"b:\", sess.run(b))\n",
    "                print(\"cross entropy: %f\" % sess.run(cross_entropy, feed_dict=feed))\n",
    "            \n",
    "        # Test model\n",
    "        correct_predictions = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "\n",
    "        # Calculate accuracy \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))   # Cast from true:1 and false:0\n",
    "        print(\"Accuracy: %f\"%sess.run(accuracy, feed_dict = {x:all_xs, y_: all_ys}))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 499 iterations\n",
      "W: [[ 3.3300729 -1.3300734]]\n",
      "b: [ 0.14253847 -0.14253835]\n",
      "cross entropy: 0.637952\n",
      "After 999 iterations\n",
      "W: [[ 5.196305  -3.1963043]]\n",
      "b: [ 0.13512911 -0.13512884]\n",
      "cross entropy: 0.609988\n",
      "After 1499 iterations\n",
      "W: [[ 6.7153406 -4.7153387]]\n",
      "b: [ 0.12940016 -0.1294001 ]\n",
      "cross entropy: 0.591472\n",
      "After 1999 iterations\n",
      "W: [[ 7.973796 -5.973794]]\n",
      "b: [ 0.12469519 -0.12469512]\n",
      "cross entropy: 0.578771\n",
      "After 2499 iterations\n",
      "W: [[ 9.032861  -7.0328565]]\n",
      "b: [ 0.12071175 -0.12071171]\n",
      "cross entropy: 0.569779\n",
      "After 2999 iterations\n",
      "W: [[ 9.935836 -7.935831]]\n",
      "b: [ 0.11727957 -0.11727951]\n",
      "cross entropy: 0.563244\n",
      "After 3499 iterations\n",
      "W: [[10.714037 -8.714031]]\n",
      "b: [ 0.11428789 -0.11428776]\n",
      "cross entropy: 0.558391\n",
      "After 3999 iterations\n",
      "W: [[11.390679 -9.390674]]\n",
      "b: [ 0.11165804 -0.11165797]\n",
      "cross entropy: 0.554723\n",
      "After 4499 iterations\n",
      "W: [[11.983359 -9.983354]]\n",
      "b: [ 0.10933124 -0.10933139]\n",
      "cross entropy: 0.551910\n",
      "After 4999 iterations\n",
      "W: [[ 12.505717 -10.505712]]\n",
      "b: [ 0.10726198 -0.10726228]\n",
      "cross entropy: 0.549724\n",
      "After 5499 iterations\n",
      "W: [[ 12.968496 -10.968491]]\n",
      "b: [ 0.10541398 -0.10541439]\n",
      "cross entropy: 0.548009\n",
      "After 5999 iterations\n",
      "W: [[ 13.380331 -11.380325]]\n",
      "b: [ 0.10375766 -0.10375819]\n",
      "cross entropy: 0.546651\n",
      "After 6499 iterations\n",
      "W: [[ 13.748233 -11.748227]]\n",
      "b: [ 0.10226871 -0.10226928]\n",
      "cross entropy: 0.545567\n",
      "After 6999 iterations\n",
      "W: [[ 14.077989 -12.077983]]\n",
      "b: [ 0.10092662 -0.10092735]\n",
      "cross entropy: 0.544697\n",
      "After 7499 iterations\n",
      "W: [[ 14.374407 -12.374401]]\n",
      "b: [ 0.09971426 -0.09971505]\n",
      "cross entropy: 0.543993\n",
      "After 7999 iterations\n",
      "W: [[ 14.641535 -12.641529]]\n",
      "b: [ 0.0986169  -0.09861775]\n",
      "cross entropy: 0.543422\n",
      "After 8499 iterations\n",
      "W: [[ 14.882811 -12.882805]]\n",
      "b: [ 0.09762183 -0.09762277]\n",
      "cross entropy: 0.542956\n",
      "After 8999 iterations\n",
      "W: [[ 15.101157 -13.101151]]\n",
      "b: [ 0.09671817 -0.09671925]\n",
      "cross entropy: 0.542574\n",
      "After 9499 iterations\n",
      "W: [[ 15.299102 -13.299096]]\n",
      "b: [ 0.09589642 -0.09589757]\n",
      "cross entropy: 0.542260\n",
      "After 9999 iterations\n",
      "W: [[ 15.478832  -13.4788265]]\n",
      "b: [ 0.09514813 -0.09514947]\n",
      "cross entropy: 0.542002\n",
      "After 10499 iterations\n",
      "W: [[ 15.64225  -13.642244]]\n",
      "b: [ 0.09446605 -0.0944676 ]\n",
      "cross entropy: 0.541788\n",
      "After 10999 iterations\n",
      "W: [[ 15.791024  -13.7910185]]\n",
      "b: [ 0.0938438  -0.09384535]\n",
      "cross entropy: 0.541611\n",
      "After 11499 iterations\n",
      "W: [[ 15.926618 -13.926612]]\n",
      "b: [ 0.09327547 -0.09327714]\n",
      "cross entropy: 0.541464\n",
      "After 11999 iterations\n",
      "W: [[ 16.050318 -14.050315]]\n",
      "b: [ 0.09275601 -0.09275784]\n",
      "cross entropy: 0.541341\n",
      "After 12499 iterations\n",
      "W: [[ 16.163277 -14.163281]]\n",
      "b: [ 0.09228089 -0.09228282]\n",
      "cross entropy: 0.541239\n",
      "After 12999 iterations\n",
      "W: [[ 16.266523 -14.266516]]\n",
      "b: [ 0.09184593 -0.09184813]\n",
      "cross entropy: 0.541154\n",
      "After 13499 iterations\n",
      "W: [[ 16.360935 -14.360936]]\n",
      "b: [ 0.09144773 -0.09144995]\n",
      "cross entropy: 0.541082\n",
      "After 13999 iterations\n",
      "W: [[ 16.447346 -14.447346]]\n",
      "b: [ 0.09108284 -0.09108508]\n",
      "cross entropy: 0.541022\n",
      "After 14499 iterations\n",
      "W: [[ 16.526478 -14.526476]]\n",
      "b: [ 0.09074828 -0.09075061]\n",
      "cross entropy: 0.540972\n",
      "After 14999 iterations\n",
      "W: [[ 16.598978 -14.598986]]\n",
      "b: [ 0.09044143 -0.09044387]\n",
      "cross entropy: 0.540930\n",
      "After 15499 iterations\n",
      "W: [[ 16.665447 -14.665454]]\n",
      "b: [ 0.09015989 -0.09016237]\n",
      "cross entropy: 0.540895\n",
      "After 15999 iterations\n",
      "W: [[ 16.726406 -14.726416]]\n",
      "b: [ 0.08990134 -0.08990408]\n",
      "cross entropy: 0.540865\n",
      "After 16499 iterations\n",
      "W: [[ 16.78234  -14.782349]]\n",
      "b: [ 0.08966398 -0.08966687]\n",
      "cross entropy: 0.540840\n",
      "After 16999 iterations\n",
      "W: [[ 16.833696 -14.833687]]\n",
      "b: [ 0.08944597 -0.08944897]\n",
      "cross entropy: 0.540819\n",
      "After 17499 iterations\n",
      "W: [[ 16.880833 -14.880832]]\n",
      "b: [ 0.08924572 -0.08924872]\n",
      "cross entropy: 0.540801\n",
      "After 17999 iterations\n",
      "W: [[ 16.92415  -14.924131]]\n",
      "b: [ 0.08906152 -0.08906478]\n",
      "cross entropy: 0.540786\n",
      "After 18499 iterations\n",
      "W: [[ 16.963902 -14.963917]]\n",
      "b: [ 0.08889242 -0.08889563]\n",
      "cross entropy: 0.540774\n",
      "After 18999 iterations\n",
      "W: [[ 17.000471 -15.000488]]\n",
      "b: [ 0.08873677 -0.08874012]\n",
      "cross entropy: 0.540763\n",
      "After 19499 iterations\n",
      "W: [[ 17.034079 -15.034097]]\n",
      "b: [ 0.08859359 -0.08859718]\n",
      "cross entropy: 0.540754\n",
      "After 19999 iterations\n",
      "W: [[ 17.064974 -15.064994]]\n",
      "b: [ 0.08846205 -0.08846558]\n",
      "cross entropy: 0.540746\n",
      "Accuracy: 0.728000\n"
     ]
    }
   ],
   "source": [
    "trainWithMultiplePointsPerEpoch(20000, train_step, dataset_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
